[
  {
    "objectID": "simulate.html",
    "href": "simulate.html",
    "title": "Generate Data",
    "section": "",
    "text": "The code below will generate a dataset of \\(n = 100\\) observations. Each observation contains several observed variables:\n\nL1 A numeric confounder\nL2 A numeric confounder\nA A binary treatment\nY A numeric outcome\n\nEach observation also contains outcomes that we know only because the data are simulated. These variables are useful as ground truth in simulations.\n\npropensity_score The true propensity score \\(P(A = 1 \\mid \\vec{L})\\)\nY0 The potential outcome under control\nY1 The potential outcome under treatment\n\nTo run this code, you will need the dplyr package. If you don’t have it, first run the line install.packages(\"dplyr\") in your R console.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nn &lt;- 100\ndata &lt;- tibble(L1 = rnorm(n),\n               L2 = rnorm(n)) |&gt;\n  # Generate potential outcomes as functions of L\n  mutate(Y0 = rnorm(n(), mean = L1 + L2, sd = 1),\n         Y1 = rnorm(n(), mean = Y0 + 1, sd = 1)) |&gt;\n  # Generate treatment as a function of L\n  mutate(propensity_score = plogis(-2 + L1 + L2)) |&gt;\n  mutate(A = rbinom(n(), 1, propensity_score)) |&gt;\n  # Generate factual outcome\n  mutate(Y = case_when(A == 0 ~ Y0,\n                       A == 1 ~ Y1))\n\nA simulation is nice because the answer is known. In this simulation, the conditional average causal effect of A on Y equals 1 at any value of L1 and L_2."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Causal Estimators",
    "section": "",
    "text": "This page offers a tutorial on causal estimators. We first designed this page for the Summer Institute in Computational Social Science at UCLA in June 2024.\nSee the first page for intuition about causal estimators. The next page provides code to simulate data. You can choose any of the subsequent pages in any order to practice applying causal estimators."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Simulate Data",
    "section": "",
    "text": "The code below will generate a dataset of \\(n = 100\\) observations. Each observation contains several observed variables:\n\nL1 A numeric confounder\nL2 A numeric confounder\nA A binary treatment\nY A numeric outcome\n\nEach observation also contains outcomes that we know only because the data are simulated. These variables are useful as ground truth in simulations.\n\npropensity_score The true propensity score \\(P(A = 1 \\mid \\vec{L})\\)\nY0 The potential outcome under control\nY1 The potential outcome under treatment\n\nTo run this code, you will need the dplyr package. If you don’t have it, first run the line install.packages(\"dplyr\") in your R console. Then, add this line to your R script to load the package.\n\nlibrary(dplyr)\n\nIf you want your simulation to match our numbers exactly, add a line to set your seed.\n\nset.seed(90095)\n\n\nn &lt;- 500\ndata &lt;- tibble(\n  L1 = rnorm(n),\n  L2 = rnorm(n)\n) |&gt;\n  # Generate potential outcomes as functions of L\n  mutate(Y0 = rnorm(n(), mean = L1 + L2, sd = 1),\n         Y1 = rnorm(n(), mean = Y0 + 1, sd = 1)) |&gt;\n  # Generate treatment as a function of L\n  mutate(propensity_score = plogis(-2 + L1 + L2)) |&gt;\n  mutate(A = rbinom(n(), 1, propensity_score)) |&gt;\n  # Generate factual outcome\n  mutate(Y = case_when(A == 0 ~ Y0,\n                       A == 1 ~ Y1))\n\nA simulation is nice because the answer is known. In this simulation, the conditional average causal effect of A on Y equals 1 at any value of L1 and L_2."
  },
  {
    "objectID": "outcomemodeling.html",
    "href": "outcomemodeling.html",
    "title": "Outcome Modeling",
    "section": "",
    "text": "Because the causal effect of A on Y is identified by adjusting for the confounders L1 and L2, we can estimate by outcome modeling.\nThe code below assumes you have generated data as on the data page."
  },
  {
    "objectID": "outcomemodeling.html#model",
    "href": "outcomemodeling.html#model",
    "title": "Outcome Modeling",
    "section": "1) Model",
    "text": "1) Model\nThe code below uses Ordinary Least Squares to estimate an outcome model.\n\nmodel &lt;- lm(Y ~ A*(L1 + L2), data = data)\n\n\n\n\nCall:\nlm(formula = Y ~ A * (L1 + L2), data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.1448 -0.7105  0.0097  0.6998  3.1743 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.01606    0.05699   0.282  0.77827    \nA            1.11555    0.18021   6.190 1.26e-09 ***\nL1           1.06333    0.05938  17.907  &lt; 2e-16 ***\nL2           1.11199    0.05951  18.685  &lt; 2e-16 ***\nA:L1        -0.39475    0.14279  -2.765  0.00591 ** \nA:L2        -0.28935    0.13940  -2.076  0.03844 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.111 on 494 degrees of freedom\nMultiple R-squared:  0.6732,    Adjusted R-squared:  0.6699 \nF-statistic: 203.6 on 5 and 494 DF,  p-value: &lt; 2.2e-16\n\n\nWe chose a model where treatment A is interacted with an additive function of confounders L1 + L2. This is also known as a t-learner (Kunzel et al. 2019) because it is equivalent to estimating two separate regression models of outcome on confounders, one among those for whom A == 1 and among those for whom A == 0."
  },
  {
    "objectID": "outcomemodeling.html#predict",
    "href": "outcomemodeling.html#predict",
    "title": "Outcome Modeling",
    "section": "2) Predict",
    "text": "2) Predict\nThe code below predicts the conditional average potential outcome under treatment and control at the confounder values of each observation.\nFirst, we create data with A set to the value 1.\n\ndata_1 &lt;- data |&gt;\n  mutate(A = 1)\n\n\n\n# A tibble: 500 × 7\n        L1     L2      Y0    Y1 propensity_score     A       Y\n     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1  0.00304  1.03   0.677   1.59          0.276       1  0.677 \n2 -2.35    -1.66  -4.09   -3.53          0.00244     1 -4.09  \n3  0.104   -0.912  0.0659  1.31          0.0569      1  0.0659\n# ℹ 497 more rows\n\n\nThen, we create data with A set to the value 0.\n\ndata_0 &lt;- data |&gt;\n  mutate(A = 0)\n\n\n\n# A tibble: 500 × 7\n        L1     L2      Y0    Y1 propensity_score     A       Y\n     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1  0.00304  1.03   0.677   1.59          0.276       0  0.677 \n2 -2.35    -1.66  -4.09   -3.53          0.00244     0 -4.09  \n3  0.104   -0.912  0.0659  1.31          0.0569      0  0.0659\n# ℹ 497 more rows\n\n\nWe use our outcome model to predict the conditional mean of the potential outcome under each scenario.\n\npredicted &lt;- data |&gt;\n  mutate(\n    Y1_predicted = predict(model, newdata = data_1),\n    Y0_predicted = predict(model, newdata = data_0),\n    effect_predicted = Y1_predicted - Y0_predicted\n  )\n\n\n\n# A tibble: 500 × 10\n        L1     L2      Y0    Y1 propensity_score     A       Y Y1_predicted\n     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n1  0.00304  1.03   0.677   1.59          0.276       0  0.677         1.98 \n2 -2.35    -1.66  -4.09   -3.53          0.00244     0 -4.09         -1.81 \n3  0.104   -0.912  0.0659  1.31          0.0569      0  0.0659        0.451\n# ℹ 497 more rows\n# ℹ 2 more variables: Y0_predicted &lt;dbl&gt;, effect_predicted &lt;dbl&gt;"
  },
  {
    "objectID": "outcomemodeling.html#aggregate",
    "href": "outcomemodeling.html#aggregate",
    "title": "Outcome Modeling",
    "section": "3) Aggregate",
    "text": "3) Aggregate\nThe final step is to aggregate to an average causal effect estimate.\n\naggregated &lt;- predicted |&gt;\n  summarize(average_effect_estimate = mean(effect_predicted))\n\n\n\n# A tibble: 1 × 1\n  average_effect_estimate\n                    &lt;dbl&gt;\n1                    1.13"
  },
  {
    "objectID": "outcomemodeling.html#closing-thoughts",
    "href": "outcomemodeling.html#closing-thoughts",
    "title": "Outcome Modeling",
    "section": "Closing thoughts",
    "text": "Closing thoughts\nOutcome modeling is a powerful strategy because it bridges nonparametric causal identification to longstanding strategies where outcomes are modeled by parametric regression.\nHere are a few things you could try next:\n\nreplace step (1) with another approach to estimate conditional mean outcomes, such as a different functional form or a machine learning method\nevaluate performance over many repeated simulations\nevaluate performance at different simulated sample sizes"
  },
  {
    "objectID": "weighting.html",
    "href": "weighting.html",
    "title": "Inverse Probability of Treatment Weighting",
    "section": "",
    "text": "Because the causal effect of A on Y is identified by adjusting for the confounders L1 and L2, we can estimate by inverse probability of treatment weighting.\nThe code below assumes you have generated data as on the data page."
  },
  {
    "objectID": "matching.html",
    "href": "matching.html",
    "title": "Matching",
    "section": "",
    "text": "Because the causal effect of A on Y is identified by adjusting for the confounders L1 and L2, we can estimate by matching treated and untreated units with similar values of these confounders.\nThere are many methods for matching. The code below walks through the particular case of propensity score matching.\nThe code below assumes you have generated data as on the data page."
  },
  {
    "objectID": "weighting.html#model",
    "href": "weighting.html#model",
    "title": "Inverse Probability of Treatment Weighting",
    "section": "1) Model",
    "text": "1) Model\nThe code below uses logistic regression to model the conditional probability of treatment.\n\nmodel &lt;- glm(\n  A ~ L1 + L2, \n  data = data, \n  family = binomial\n)\n\n\n\n\nCall:\nglm(formula = A ~ L1 + L2, family = binomial, data = data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -2.0740     0.1737 -11.938  &lt; 2e-16 ***\nL1            1.0845     0.1639   6.618 3.65e-11 ***\nL2            1.1877     0.1548   7.673 1.68e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 474.41  on 499  degrees of freedom\nResidual deviance: 354.86  on 497  degrees of freedom\nAIC: 360.86\n\nNumber of Fisher Scoring iterations: 5"
  },
  {
    "objectID": "weighting.html#predict",
    "href": "weighting.html#predict",
    "title": "Inverse Probability of Treatment Weighting",
    "section": "2) Predict",
    "text": "2) Predict\nThe code below predicts the conditional probability of each unit’s observed treatment value, also known as the propensity score.\n\npredicted &lt;- data |&gt;\n  # Predict the probabilities that A = 1 and A = 0\n  mutate(\n    p_A_equals_1 = predict(model, type = \"response\"),\n    p_A_equals_0 = 1 - p_A_equals_1\n  ) |&gt;\n  # Assign the propensity score based on the observed treatment\n  mutate(\n    pi = case_when(\n      A == 1 ~ p_A_equals_1,\n      A == 0 ~ p_A_equals_0\n    )\n  )\n\n\n\n# A tibble: 500 × 10\n        L1     L2      Y0    Y1 propensity_score     A       Y p_A_equals_1\n     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n1  0.00304  1.03   0.677   1.59          0.276       0  0.677       0.300  \n2 -2.35    -1.66  -4.09   -3.53          0.00244     0 -4.09        0.00136\n3  0.104   -0.912  0.0659  1.31          0.0569      0  0.0659      0.0455 \n# ℹ 497 more rows\n# ℹ 2 more variables: p_A_equals_0 &lt;dbl&gt;, pi &lt;dbl&gt;"
  },
  {
    "objectID": "weighting.html#aggregate",
    "href": "weighting.html#aggregate",
    "title": "Inverse Probability of Treatment Weighting",
    "section": "3) Aggregate",
    "text": "3) Aggregate\nThe final step is to aggregate to an average causal effect estimate.\n\naggregated_Y1 &lt;- predicted |&gt;\n  # Restrict to cases with A == 1\n  filter(A == 1) |&gt;\n  # Calculate the weighted mean outcome\n  summarize(estimate = weighted.mean(Y, w = 1 / pi))\n\naggregated_Y0 &lt;- predicted |&gt;\n  # Restrict to cases with A == 1\n  filter(A == 0) |&gt;\n  # Calculate the weighted mean outcome\n  summarize(estimate = weighted.mean(Y, w = 1 / pi))\n\naverage_effect_estimate &lt;- aggregated_Y1 - aggregated_Y0\n\n\n\n  estimate\n1 1.288555"
  },
  {
    "objectID": "weighting.html#closing-thoughts",
    "href": "weighting.html#closing-thoughts",
    "title": "Inverse Probability of Treatment Weighting",
    "section": "Closing thoughts",
    "text": "Closing thoughts\nInverse probability of treatment weighting is a powerful strategy because it bridges nonparametric causal identification to longstanding strategies from survey sampling where units from a population are sampled with known probabilities of inclusion. The analogy is that outcomes under treatment are sampled with estimated inclusion probabilities (the probability of treatment). Just as in a population sample we would need to think carefully about the probability of sampling, treatment modeling encourages us to model the probability of receiving the observed treatment.\nHere are a few things you could try next:\n\nreplace step (1) with another approach to estimate conditional treatment probabilities, such as a different functional form or a machine learning method\nevaluate performance over many repeated simulations\nevaluate performance at different simulated sample sizes"
  },
  {
    "objectID": "matching.html#target-population",
    "href": "matching.html#target-population",
    "title": "Matching",
    "section": "1) Target population",
    "text": "1) Target population\nWhile the target population is relevant to all causal estimands and estimators, it is especially apparent when matching. One might choose\n\naverage treatment effect (ATE): the average over all units\naverage treatment effect on the treated (ATT): the average effect among units who received the treatment\naverage treatment effect on the control (ATC): the average effect among units who did not receive the treatment\n\nWe will focus on the ATT, which means we will take each treated unit and seek to find a matching control unit with similar values of the confounders. If we instead studied the ATC, we would take each control unit and seek to find a matching treated unit with similar values of the confounders. The ATT and ATC will generally be different to the degree that effects and treatment probabilities both vary across values of the confounders."
  },
  {
    "objectID": "matching.html#distance-metric",
    "href": "matching.html#distance-metric",
    "title": "Matching",
    "section": "2) Distance metric",
    "text": "2) Distance metric\nSuppose one unit has confounder values \\(\\{\\ell_1,\\ell_2\\}\\) and another unit has confounder value \\(\\{\\ell_1',\\ell_2'\\}\\). There are many ways to define the distance between these units.\n\nEuclidean distance: square root of sum of squared differences on each variable \\[d\\left(\\vec\\ell,\\vec\\ell'\\right) = \\sqrt{(\\ell_1 - \\ell_1')^2 + (\\ell_2 - \\ell_2')^2}\\]\nManhattan distance: sum of absolute difference on each variable \\[d\\left(\\vec\\ell,\\vec\\ell'\\right) = \\lvert\\ell_1 - \\ell_1'\\rvert + \\lvert\\ell_2 - \\ell_2'\\rvert\\]\nPropensity score distance: difference in the conditional probability of being treated \\[d\\left(\\vec\\ell,\\vec\\ell'\\right) = \\left\\lvert P\\left(A = 1\\mid L_1 = \\ell_1, L_2 = \\ell_2\\right) - P\\left(A = 1\\mid L_1 = \\ell_1', L_2 = \\ell_2'\\right)\\right\\rvert\\]"
  },
  {
    "objectID": "matching.html#matching-method",
    "href": "matching.html#matching-method",
    "title": "Matching",
    "section": "3) Matching method",
    "text": "3) Matching method\nThere are many ways to match units given the distance metric.\n\nNumber of matches\n\nIn 1:1 matching, each treated unit is matched to one control unit\nIn 1:k matching, each treated unit is matched to k control units\nIn other varieties, the ratio is allowed to differ across units.\n\n\n\nSequence of matching\n\nGreedy matching begins with the first treated unit and finds the best control unit, removing it from the eligible pool. This control unit may be a good match for the second treated unit but is no longer available\nOptimal matching finds the optimal pairs over all the units, but is more compute-intensive"
  },
  {
    "objectID": "matching.html#aggregate",
    "href": "matching.html#aggregate",
    "title": "Matching",
    "section": "4) Aggregate",
    "text": "4) Aggregate\nThe final step is to aggregate, with two main options\n\ndifference the mean \\(Y\\) among matched treated and control units\nmodel \\(Y\\) given treatment and confounders among the matched set\n\nWhile (a) is simpler, (b) is often preferred because it correct for differences in the confounder values that persist even after matching."
  },
  {
    "objectID": "matching.html#code-illustration",
    "href": "matching.html#code-illustration",
    "title": "Matching",
    "section": "Code illustration",
    "text": "Code illustration\nThe MatchIt package is one way to implement various matching strategies. You can install with install.package(\"MatchIt\") in your R console.\n\nlibrary(MatchIt)\n\nThe code below uses MatchIt to conduct nearest-neighbor 1:1 propensity score matching.\n\nmatched &lt;- matchit(\n  A ~ L1 + L2,\n  data = data, \n  distance = \"glm\",\n  method = \"nearest\"\n)\n\nThe code below appends the matching weights to the data. Units with match_weight == 1 are matched, while those with match_weight == 0 are unmatched.\n\n# Append matching weights to the data\nwith_weights &lt;- data |&gt;\n  mutate(match_weight = matched$weights) |&gt;\n  select(A, L1, L2, Y, match_weight)\n\n\n\n# A tibble: 500 × 5\n       A       L1      L2       Y match_weight\n   &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n 1     0  0.00304  1.03    0.677             1\n 2     0 -2.35    -1.66   -4.09              0\n 3     0  0.104   -0.912   0.0659            0\n 4     0 -0.522    0.439   0.390             0\n 5     0 -1.18    -0.815  -2.14              0\n 6     0  0.477   -0.0314  0.396             0\n 7     0 -0.0607  -0.462  -1.96              0\n 8     0  0.987    0.426   2.27              1\n 9     0 -0.122   -0.564  -0.0581            0\n10     0 -1.34    -0.618  -2.73              0\n# ℹ 490 more rows\n\n\nThe code below estimates the ATT by OLS regression on the matched set.\n\nmodel &lt;- lm(\n  Y ~ A + L1 + L2,\n  data = with_weights,\n  weights = match_weight\n)\nsummary(model)\n\n\nCall:\nlm(formula = Y ~ A + L1 + L2, data = with_weights, weights = match_weight)\n\nWeighted Residuals:\n   Min     1Q Median     3Q    Max \n-4.150  0.000  0.000  0.000  3.297 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   0.2674     0.1641   1.630 0.104923    \nA             0.6716     0.1964   3.419 0.000779 ***\nL1            0.8176     0.1144   7.143 2.25e-11 ***\nL2            0.9689     0.1119   8.656 2.86e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.311 on 178 degrees of freedom\nMultiple R-squared:  0.4097,    Adjusted R-squared:  0.3998 \nF-statistic: 41.18 on 3 and 178 DF,  p-value: &lt; 2.2e-16\n\n\nThe coefficient on the treatment A is an estiamte of the ATT."
  },
  {
    "objectID": "matching.html#closing-thoughts",
    "href": "matching.html#closing-thoughts",
    "title": "Matching",
    "section": "Closing thoughts",
    "text": "Closing thoughts\nMatching is a powerful strategy because it bridges nonparametric causal identification to a concrete idea: match each treated unit to a similar unit that wasn’t treated.\nHere are a few things you could try next:\n\ntype ?matchit to learn about other arguments that could modify the distance metric or matching method\nevaluate performance over many repeated simulations\nevaluate performance at different simulated sample sizes"
  },
  {
    "objectID": "intuition.html",
    "href": "intuition.html",
    "title": "Building Intuition",
    "section": "",
    "text": "Before diving into a more complex simulated setting, this page builds intuition for causal estimators in a simple setting with only 6 observations. At confounder value 1, 2 out of 3 are treated. At confounder value 2, 1 out of 3 is treated.\nWe assume causal identification given the confounder. The causal problem is to use the observed data to learn about the missing values."
  },
  {
    "objectID": "intuition.html#outcome-modeling",
    "href": "intuition.html#outcome-modeling",
    "title": "Building Intuition",
    "section": "Outcome modeling",
    "text": "Outcome modeling\nOne strategy is to estimate an outcome model for the conditional mean of the observed outcomes.\n\\[E(Y\\mid A, X) = \\alpha + \\beta X + \\gamma A\\]\nIn these data, we would estimate \\(\\hat\\alpha = 0\\), \\(\\hat\\beta = 1\\), and \\(\\hat\\gamma = 1\\). We could then predict the counterfactual outcomes."
  },
  {
    "objectID": "intuition.html#inverse-probability-weighting",
    "href": "intuition.html#inverse-probability-weighting",
    "title": "Building Intuition",
    "section": "Inverse probability weighting",
    "text": "Inverse probability weighting\nAnother strategy is to consider the treated units as a sample of all units, drawn with unequal probabilities across confounder values. Likewise, for the control units. Just as in sampling we would weight by the inverse probability of sample inclusion, we can weight by the inverse probability of the observed treatment."
  },
  {
    "objectID": "intuition.html#matching",
    "href": "intuition.html#matching",
    "title": "Building Intuition",
    "section": "Matching",
    "text": "Matching\nA third is to find for each unit a matched case that had the other treatment condition. We then impute the missing outcome value by the observed outcome of the matched case.\n\nMatching can be conceptualized as a special case of outcome modeling, where the outcome model is a nearest neighbor estimator."
  },
  {
    "objectID": "intuition.html#what-to-do-next",
    "href": "intuition.html#what-to-do-next",
    "title": "Building Intuition",
    "section": "What to do next",
    "text": "What to do next\nNow that you have a conceptual idea of these strategies, move on to the next pages to practice them with simulated data."
  }
]